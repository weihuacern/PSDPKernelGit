{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# This class is for the preprocessing, take csv path as input, and aim to return a pandas data frame for trainning\n",
    "class PreProcessing:\n",
    "\n",
    "  # The constructor takes a pandas dataframe as input and save it to self.df\n",
    "  def __init__(self, csvpath):\n",
    "    self.df = pd.read_csv(csvpath)\n",
    "    if \"train\" in csvpath:\n",
    "      self.dftype = 1\n",
    "    elif \"test\" in csvpath:\n",
    "      self.dftype = 2\n",
    "    else:\n",
    "      self.dftype = -1\n",
    "\n",
    "  # This method have deal with missing data before merge or drop\n",
    "  def MissingData(self):\n",
    "    self.df = self.df.replace(-1, np.NaN) #first, replace -1 to NaN\n",
    "    #print (self.df.columns[self.df.isnull().any()])\n",
    "    '''\n",
    "    'ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', \n",
    "    'ps_reg_03',\n",
    "    'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_05_cat', 'ps_car_07_cat', 'ps_car_09_cat', \n",
    "    'ps_car_11', 'ps_car_12', 'ps_car_14'\n",
    "    '''\n",
    "    mean_imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "    mdan_imp = Imputer(missing_values='NaN', strategy='median', axis=0)\n",
    "    mfrq_imp = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)\n",
    "\n",
    "    self.df[\"ps_ind_02_cat\"].fillna(-1, inplace=True)\n",
    "    self.df[\"ps_ind_04_cat\"].fillna(-1, inplace=True)\n",
    "    self.df[\"ps_ind_05_cat\"].fillna(-1, inplace=True)\n",
    "    #self.df[\"ps_reg_03\"].fillna(self.df[\"ps_reg_03\"].median(), inplace=True)\n",
    "    #self.df['ps_reg_03'] = mean_imp.fit_transform(self.df[['ps_reg_03']]).ravel()\n",
    "    self.df[\"ps_reg_03\"].fillna(2 * self.df['ps_reg_03'].value_counts().idxmax(), inplace=True)\n",
    "    self.df[\"ps_car_01_cat\"].fillna(-1, inplace=True)\n",
    "    self.df[\"ps_car_02_cat\"].fillna(-1, inplace=True)\n",
    "    #self.df[\"ps_car_03_cat\"].fillna(self.df[\"ps_car_03_cat\"].value_counts().idxmax(), inplace=True) # top 1 missing variable, drop\n",
    "    #self.df[\"ps_car_05_cat\"].fillna(self.df[\"ps_car_05_cat\"].value_counts().idxmax(), inplace=True) # top 2 missing variable, drop\n",
    "    self.df[\"ps_car_03_cat\"].fillna(-1, inplace=True) # top 1 missing variable\n",
    "    self.df[\"ps_car_05_cat\"].fillna(-1, inplace=True) # top 2 missing variable\n",
    "    self.df[\"ps_car_07_cat\"].fillna(-1, inplace=True)\n",
    "    self.df[\"ps_car_09_cat\"].fillna(-1, inplace=True)\n",
    "    #self.df[\"ps_car_11\"].fillna(self.df[\"ps_car_11\"].value_counts().idxmax(), inplace=True)\n",
    "    self.df[\"ps_car_11\"].fillna(-1, inplace=True) # this is catually a cat variable, inverted with ps_car_11_cat\n",
    "    #self.df['ps_car_11'] = mfrq_imp.fit_transform(self.df[['ps_car_11']]).ravel()\n",
    "    #self.df[\"ps_car_12\"].fillna(self.df[\"ps_car_12\"].median(), inplace=True)\n",
    "    #self.df['ps_car_12'] = mean_imp.fit_transform(self.df[['ps_car_12']]).ravel()\n",
    "    self.df['ps_car_12'].fillna(2 * self.df['ps_car_12'].value_counts().idxmax(), inplace=True)\n",
    "    #self.df[\"ps_car_14\"].fillna(self.df[\"ps_car_14\"].median(), inplace=True)\n",
    "    #self.df['ps_car_14'] = mean_imp.fit_transform(self.df[['ps_car_14']]).ravel()\n",
    "    self.df[\"ps_car_14\"].fillna(2 * self.df['ps_car_14'].value_counts().idxmax(), inplace=True)\n",
    "\n",
    "    #self.df[\"\"].fillna(self.df[\"\"].mean(), inplace=True)\n",
    "    #self.df[\"\"].fillna(self.df[\"\"].median(), inplace=True)\n",
    "    #self.df[\"\"].fillna(self.df[\"\"].value_counts().idxmax(), inplace=True)\n",
    "    return\n",
    "\n",
    "  # This method drop the original catagory labels and replaced with one hot labels\n",
    "  def OneHotReplacement(self):\n",
    "\n",
    "    #onehot_cols = ['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat', 'ps_car_05_cat', 'ps_car_07_cat', 'ps_car_09_cat', 'ps_car_10_cat', 'ps_car_11']\n",
    "    onehot_cols = ['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat', 'ps_car_05_cat', 'ps_car_07_cat', 'ps_car_09_cat', 'ps_car_11']\n",
    "\n",
    "    self.df = pd.get_dummies(self.df, columns=onehot_cols, drop_first=True)\n",
    "    #onehot = pd.get_dummies(self.df['ps_ind_02_cat'])\n",
    "    #self.df.drop(['ps_ind_02_cat'], axis = 1, inplace = True)\n",
    "    #self.df = self.df.join(onehot)\n",
    "    return\n",
    "\n",
    "  # This method drop or merge variables in dataframe accroding to corr map\n",
    "  def CorrMergeDrop(self):\n",
    "    #self.df['ps_ind_06070809_bin'] = self.df.apply(\n",
    "    #  lambda x: 1 if x['ps_ind_06_bin'] == 1 \n",
    "    #              else \n",
    "    #              (2 if x['ps_ind_07_bin'] == 1 \n",
    "    #                 else \n",
    "    #                 ( 3 if x['ps_ind_08_bin'] == 1 \n",
    "    #                     else \n",
    "    #                     (4 if x['ps_ind_09_bin'] == 1 else 5)\n",
    "    #                 )\n",
    "    #              ), axis = 1)\n",
    "    #self.df.drop(['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin'], axis = 1, inplace = True)\n",
    "\n",
    "    #self.df['ps_ind_161718_bin'] = self.df.apply(lambda x: 1 if x['ps_ind_16_bin'] == 1 \n",
    "    #                                                         else (2 if x['ps_ind_17_bin'] == 1 else 3), axis = 1)\n",
    "    #self.df.drop(['ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin'], axis = 1, inplace = True)\n",
    " \n",
    "    # drop this variable from preprocessing study, top 3 missing data, and not important at all\n",
    "    #self.df.drop(['ps_car_03_cat'], axis = 1, inplace = True)\n",
    "    #self.df.drop(['ps_car_05_cat'], axis = 1, inplace = True)\n",
    "    # drop less important features, random forest\n",
    "    #'''\n",
    "    #self.df.drop(['ps_calc_15_bin'], axis = 1, inplace = True)\n",
    "    #self.df.drop(['ps_calc_16_bin'], axis = 1, inplace = True)\n",
    "    #self.df.drop(['ps_calc_17_bin'], axis = 1, inplace = True)\n",
    "    #self.df.drop(['ps_calc_18_bin'], axis = 1, inplace = True)\n",
    "    #self.df.drop(['ps_calc_19_bin'], axis = 1, inplace = True)\n",
    "    #self.df.drop(['ps_calc_20_bin'], axis = 1, inplace = True)\n",
    "    self.df.drop(['ps_ind_10_bin'], axis = 1, inplace = True)\n",
    "    self.df.drop(['ps_ind_11_bin'], axis = 1, inplace = True)\n",
    "    self.df.drop(['ps_ind_12_bin'], axis = 1, inplace = True)\n",
    "    self.df.drop(['ps_ind_13_bin'], axis = 1, inplace = True)\n",
    "    #self.df.drop(['ps_ind_14'], axis = 1, inplace = True)\n",
    "    #self.df.drop(['ps_car_04_cat'], axis = 1, inplace = True)\n",
    "    self.df.drop(['ps_car_10_cat'], axis = 1, inplace = True)\n",
    "    #'''\n",
    "    #self.df['ps_car_13'] = (self.df['ps_car_13']*self.df['ps_car_13']*48400).round(0)\n",
    "    #self.df['ps_car_12'] = (self.df['ps_car_12']*self.df['ps_car_12']).round(4) * 10000\n",
    "    return\n",
    "\n",
    "  # scale the features \n",
    "  def ScaleFeatures(self):\n",
    "    scaler = StandardScaler(copy=False)\n",
    "    if self.dftype == 1:\n",
    "      scaler.fit_transform(self.df.drop(['id','target'], axis=1))\n",
    "    elif self.dftype == 2:\n",
    "      scaler.fit_transform(self.df.drop(['id'], axis=1))\n",
    "    else:\n",
    "      print (\"neither train nor test!\")\n",
    "    return\n",
    "\n",
    "  # this method pack all previous preprocessing all together and return the data frame\n",
    "  def FinalFrameforTrainning(self):\n",
    "    self.MissingData()\n",
    "    self.OneHotReplacement()\n",
    "    self.CorrMergeDrop()\n",
    "    self.ScaleFeatures()\n",
    "    #print (self.df)\n",
    "    return self.df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with trainning set preprocessing!\n",
      "done with test set preprocessing!\n"
     ]
    }
   ],
   "source": [
    "preprocessing = PreProcessing('../data/train.csv')\n",
    "train_p = preprocessing.FinalFrameforTrainning()\n",
    "print (\"done with trainning set preprocessing!\")\n",
    "#train_p.to_csv('train_p.csv', index = False)\n",
    "preprocessing = PreProcessing('../data/test.csv')\n",
    "test_p = preprocessing.FinalFrameforTrainning()\n",
    "print (\"done with test set preprocessing!\")\n",
    "#test_p.to_csv('test_p.csv', index = False)\n",
    "#train_p = pd.read_csv('train_p.csv')\n",
    "#test_p = pd.read_csv('test_p.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(595212, 94)\n",
      "(892816, 93)\n"
     ]
    }
   ],
   "source": [
    "#print(train_p.head())\n",
    "print(train_p.shape)\n",
    "print(test_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hua/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nX_train, X_test, y_train, y_test = train_test_split(\\n                                                    train_p.drop([\\'id\\', \\'target\\'],axis=1),\\n                                                    train_p.target,\\n                                                    train_size=0.7,\\n                                                    test_size=0.3,\\n                                                    random_state=0\\n                                                   )\\n#xgb = XGBClassifier(    \\n#                    n_estimators=1000,\\n#                    max_depth=6,\\n#                    objective=\"binary:logistic\",\\n#                    learning_rate=0.07, \\n#                    subsample=.8,\\n#                    min_child_weight=.77,\\n#                    colsample_bytree=.8,\\n#                    scale_pos_weight=1.6,\\n#                    gamma=10,\\n#                    reg_alpha=8,\\n#                    reg_lambda=1.3,\\n#                    )\\n\\nxgb = XGBClassifier(n_estimators=1000, objective=\"binary:logistic\", learning_rate=0.014, max_depth=4, min_child_weight=5, gamma=0, subsample=0.8, colsample_bytree=0.8,  reg_alpha=0, reg_lambda=1, nthread=6)\\n                    \\nxgb.fit(X_train, y_train)\\nprint(\"----- Training Done -----\")\\nysc_pred = xgb.predict_proba(X_test)[:,1]\\n#print (ysc_pred)\\n#print (y_test)\\ngini = 2*roc_auc_score(y_test, ysc_pred)-1\\nprint(gini)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "\n",
    "'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                                    train_p.drop(['id', 'target'],axis=1),\n",
    "                                                    train_p.target,\n",
    "                                                    train_size=0.7,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0\n",
    "                                                   )\n",
    "#xgb = XGBClassifier(    \n",
    "#                    n_estimators=1000,\n",
    "#                    max_depth=6,\n",
    "#                    objective=\"binary:logistic\",\n",
    "#                    learning_rate=0.07, \n",
    "#                    subsample=.8,\n",
    "#                    min_child_weight=.77,\n",
    "#                    colsample_bytree=.8,\n",
    "#                    scale_pos_weight=1.6,\n",
    "#                    gamma=10,\n",
    "#                    reg_alpha=8,\n",
    "#                    reg_lambda=1.3,\n",
    "#                    )\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=1000, objective=\"binary:logistic\", learning_rate=0.014, max_depth=4, min_child_weight=5, gamma=0, subsample=0.8, colsample_bytree=0.8,  reg_alpha=0, reg_lambda=1, nthread=6)\n",
    "                    \n",
    "xgb.fit(X_train, y_train)\n",
    "print(\"----- Training Done -----\")\n",
    "ysc_pred = xgb.predict_proba(X_test)[:,1]\n",
    "#print (ysc_pred)\n",
    "#print (y_test)\n",
    "gini = 2*roc_auc_score(y_test, ysc_pred)-1\n",
    "print(gini)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-950afa4744af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m x, y = (list(x) for x in zip(*sorted(zip(xgb.feature_importances_, features), \n\u001b[0m\u001b[1;32m      3\u001b[0m                                                             reverse = False)))\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#print(y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mindice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "features = train_p.drop(['id', 'target'],axis=1).columns.values\n",
    "x, y = (list(x) for x in zip(*sorted(zip(xgb.feature_importances_, features), \n",
    "                                                            reverse = False)))\n",
    "#print(y)\n",
    "indice = 0\n",
    "for thisy in y:\n",
    "    if 'ps_ind' in thisy:\n",
    "        print(indice)\n",
    "        print(y[indice])\n",
    "        print(x[indice])\n",
    "    indice = indice+1\n",
    "\n",
    "trace2 = go.Bar(\n",
    "    x=x ,\n",
    "    y=y,\n",
    "    marker=dict(\n",
    "        color=x,\n",
    "        colorscale = 'Viridis',\n",
    "        reversescale = True\n",
    "    ),\n",
    "    name='XGBoost Feature importance',\n",
    "    orientation='h',\n",
    ")\n",
    "\n",
    "layout = dict(\n",
    "    title='Feature importances, XGBoost',\n",
    "     width = 900, height = 2000,\n",
    "    yaxis=dict(\n",
    "        showgrid=False,\n",
    "        showline=False,\n",
    "        showticklabels=True,\n",
    "#         domain=[0, 0.85],\n",
    "    ))\n",
    "\n",
    "fig1 = go.Figure(data=[trace2])\n",
    "fig1['layout'].update(layout)\n",
    "py.iplot(fig1, filename='plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def xgb_param_selection(nfolds):\n",
    "    #sc_mod = XGBClassifier(n_estimators=100, objective=\"binary:logistic\", learning_rate=0.1, subsample=0.8, colsample_bytree=0.8, nthread=6)\n",
    "    #sc_mod = XGBClassifier(n_estimators=100, objective=\"binary:logistic\", learning_rate=0.1, max_depth=4, min_child_weight=5, subsample=0.8, colsample_bytree=0.8, nthread=6)\n",
    "    #sc_mod = XGBClassifier(n_estimators=100, objective=\"binary:logistic\", learning_rate=0.1, max_depth=4, min_child_weight=5, gamma=0, nthread=6)\n",
    "    #sc_mod = XGBClassifier(n_estimators=100, objective=\"binary:logistic\", learning_rate=0.1, max_depth=4, min_child_weight=5, gamma=0, subsample=0.8, colsample_bytree=0.8, nthread=6)\n",
    "    #sc_mod = XGBClassifier(objective=\"binary:logistic\", max_depth=4, min_child_weight=5, gamma=0, subsample=0.8, colsample_bytree=0.8, reg_alpha=0, reg_lambda=1, nthread=6)\n",
    "    #sc_mod = XGBClassifier(n_estimators=1000, objective=\"binary:logistic\", learning_rate=0.14, subsample=0.8, colsample_bytree=0.8, nthread=6)\n",
    "    #sc_mod = XGBClassifier(n_estimators=400, objective=\"binary:logistic\", learning_rate=0.07, max_depth=4, min_child_weight=6, gamma=10, subsample=0.8, colsample_bytree=0.8, reg_alpha=8, reg_lambda=1.3, nthread=6)\n",
    "    #sc_mod = XGBClassifier(n_estimators=700, objective=\"binary:logistic\", learning_rate=0.025, max_depth=7, min_child_weight=10, gamma=0.65, subsample=0.8, colsample_bytree=0.4, max_delta_step=1.8, nthread=6)\n",
    "    sc_mod = XGBClassifier(n_estimators=400, objective=\"binary:logistic\", learning_rate=0.07, max_depth=5, min_child_weight=100, gamma=1.5, subsample=0.9, colsample_bytree=0.9, nthread=6)\n",
    "    \n",
    "    sposw = [1.0]\n",
    "    param_grid = {'scale_pos_weight': sposw}    \n",
    "    #mchdw = [1,3,5]\n",
    "    #mdeps = [3,4,5,6,8,10,12]\n",
    "    #mchdw = [1,2,3,4,5,6,7]\n",
    "    #mdeps = [4]\n",
    "    #mchdw = [5]\n",
    "    #mdeps = [4]\n",
    "    #param_grid = {'min_child_weight' : mchdw, 'max_depth': mdeps}\n",
    "    #mnsps = [0.0, 0.05, 0.1, 0.15, 0.2, 0.25]\n",
    "    #param_grid = {'gamma' : mnsps}\n",
    "    #subss = [0.6, 0.7, 0.8, 0.9]\n",
    "    #colst = [0.6, 0.7, 0.8, 0.9]\n",
    "    #param_grid = {'subsample' : subss, 'colsample_bytree': colst}\n",
    "    #regl1 = [0]\n",
    "    #regl2 = [0, 0.01, 0.1, 1, 10, 100]\n",
    "    #regl1 = [0, 0.1, 1, 10]\n",
    "    #regl2 = [0.1, 1]\n",
    "    #param_grid = {'reg_alpha' : regl1, 'reg_lambda': regl2}\n",
    "    #nests = [100, 200, 500, 1000]\n",
    "    #lrate = [0.01, 0.1, 1]\n",
    "    #nests = [1000]\n",
    "    #lrate = [0.005, 0.01, 0.015, 0.02]\n",
    "    #nests = [1000]\n",
    "    #lrate = [0.011, 0.012, 0.013, 0.014, 0.015]      \n",
    "    #param_grid = {'n_estimators': nests, 'learning_rate' : lrate}\n",
    "    grid_search = GridSearchCV(sc_mod, param_grid, scoring='roc_auc', cv=nfolds, verbose=2)\n",
    "    grid_search.fit(train_p.drop(['id', 'target'],axis=1), train_p.target)\n",
    "    #print (\"CV results\")\n",
    "    #print (grid_search.cv_results_)\n",
    "    print (\"Grid Scores:\")\n",
    "    print (grid_search.grid_scores_)\n",
    "    print (\"Best parameters:\")\n",
    "    print (grid_search.best_params_)\n",
    "    return grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] scale_pos_weight=1.0 ............................................\n",
      "[CV] ............................. scale_pos_weight=1.0, total= 1.5min\n",
      "[CV] scale_pos_weight=1.0 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................. scale_pos_weight=1.0, total= 1.5min\n",
      "[CV] scale_pos_weight=1.0 ............................................\n",
      "[CV] ............................. scale_pos_weight=1.0, total= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  4.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Scores:\n",
      "[mean: 0.63849, std: 0.00271, params: {'scale_pos_weight': 1.0}]\n",
      "Best parameters:\n",
      "{'scale_pos_weight': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hua/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning:\n",
      "\n",
      "The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "\n",
      "/home/hua/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning:\n",
      "\n",
      "You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "\n",
      "/home/hua/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning:\n",
      "\n",
      "You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "\n",
      "/home/hua/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning:\n",
      "\n",
      "You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "\n",
      "/home/hua/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning:\n",
      "\n",
      "You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "\n",
      "/home/hua/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning:\n",
      "\n",
      "You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 89.01271876]),\n",
       " 'mean_score_time': array([ 1.01508403]),\n",
       " 'mean_test_score': array([ 0.63849366]),\n",
       " 'mean_train_score': array([ 0.71148345]),\n",
       " 'param_scale_pos_weight': masked_array(data = [1.0],\n",
       "              mask = [False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'scale_pos_weight': 1.0}],\n",
       " 'rank_test_score': array([1], dtype=int32),\n",
       " 'split0_test_score': array([ 0.63586876]),\n",
       " 'split0_train_score': array([ 0.71242927]),\n",
       " 'split1_test_score': array([ 0.6422216]),\n",
       " 'split1_train_score': array([ 0.70986799]),\n",
       " 'split2_test_score': array([ 0.63739063]),\n",
       " 'split2_train_score': array([ 0.7121531]),\n",
       " 'std_fit_time': array([ 1.45276944]),\n",
       " 'std_score_time': array([ 0.00849706]),\n",
       " 'std_test_score': array([ 0.00270828]),\n",
       " 'std_train_score': array([ 0.00114786])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_param_selection(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Training Done -----\n",
      "[[ 0.97268504  0.02731498]\n",
      " [ 0.97487372  0.02512625]\n",
      " [ 0.9721278   0.0278722 ]\n",
      " ..., \n",
      " [ 0.96019721  0.03980282]\n",
      " [ 0.97476858  0.02523141]\n",
      " [ 0.97046328  0.02953671]]\n"
     ]
    }
   ],
   "source": [
    "# final block, rm after tuning\n",
    "xgb_final = XGBClassifier(n_estimators=1000, objective=\"binary:logistic\", learning_rate=0.014, max_depth=4, min_child_weight=5, gamma=0, subsample=0.8, colsample_bytree=0.8,  reg_alpha=0, reg_lambda=1, nthread=6)\n",
    "xgb_final.fit(train_p.drop(['id', 'target'],axis=1), train_p.target)\n",
    "print(\"----- Training Done -----\")\n",
    "pred_final = xgb_final.predict_proba(test_p.drop(['id'],axis=1))\n",
    "print(pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.027315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.025126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.027872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.015160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.034867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    target\n",
       "0   0  0.027315\n",
       "1   1  0.025126\n",
       "2   2  0.027872\n",
       "3   3  0.015160\n",
       "4   4  0.034867"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate submission file\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = test_p.id\n",
    "sub['target'] = pred_final[:,1]\n",
    "sub.to_csv('../data/res/submit_PreOneHotDrop_XGB_20171127.csv', index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
